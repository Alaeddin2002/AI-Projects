{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "def rebuild(dict,feature):\n",
    "    elements = {}\n",
    "    index = 0\n",
    "    for x in dict.keys():\n",
    "        if x == feature:\n",
    "            for value in dict[x]:\n",
    "                if value in elements.keys():\n",
    "                    elements[value].append(index)\n",
    "                else:\n",
    "                    elements[value] = []\n",
    "                    elements[value].append(index)\n",
    "                index += 1\n",
    "    outerDict = {}\n",
    "    for x in elements.keys():\n",
    "        innerDict = {}\n",
    "        for y in dict.keys():\n",
    "            if y != feature:\n",
    "                innerDict[y] = []\n",
    "                for value in elements[x]:\n",
    "                    innerDict[y].append(dict[y][value])\n",
    "                outerDict[x] = innerDict\n",
    "    return outerDict\n",
    "\n",
    "def split(node,feature):\n",
    "    node._featureSplit = feature\n",
    "    data = rebuild(node._dataDict,feature)\n",
    "    for key in data.keys():\n",
    "        yesCount = 0\n",
    "        noCount = 0\n",
    "        values = list(data[key].values())\n",
    "        classificationCol = values[len(values)-1]\n",
    "        for value in classificationCol:\n",
    "            if value == 'yes':\n",
    "                yesCount += 1\n",
    "            else:\n",
    "                noCount += 1\n",
    "        total = yesCount + noCount\n",
    "        if yesCount > noCount:\n",
    "            percent = \"{:.0%}\".format(yesCount/total)\n",
    "            classification = 'yes, '+ \"Percentage accuracy: \"  + str(percent)\n",
    "        else:\n",
    "            percent = \"{:.0%}\".format(noCount/total)\n",
    "            classification = 'no, ' + \"Percentage accuracy: \" + str(percent)\n",
    "        newNode = Node(data[key],classification)\n",
    "        data[key] = newNode\n",
    "    node.childrenDict = data\n",
    "\n",
    "def build_tree(node):\n",
    "    if (len(node._dataDict) == 1):\n",
    "        return node.classification\n",
    "    entropies = attribute_entropies(node._dataDict)\n",
    "    lowest_feat = smallest_entropy(entropies)\n",
    "    split(node,list(lowest_feat.keys())[0])\n",
    "    for i in range(0,len(node.childrenDict)):\n",
    "        build_tree(node.childrenDict[list(node.childrenDict.keys())[i]])\n",
    "\n",
    "def smallest_entropy(dict):\n",
    "    lowest = 2\n",
    "    for key in dict:\n",
    "        if dict[key] < lowest:\n",
    "            lowest = dict[key]\n",
    "            lowestDict = {key : dict[key]}\n",
    "    return lowestDict\n",
    "\n",
    "def visualize(node,space):\n",
    "    if node.childrenDict == None:\n",
    "        return 0\n",
    "    space += \"   \"\n",
    "    for key in node.childrenDict:\n",
    "        print(space + node._featureSplit + \" = \" + key + \": \" + node.childrenDict[key].classification)\n",
    "        visualize(node.childrenDict[key],space)\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,dataDict,classification):\n",
    "        self._featureSplit = None\n",
    "        self._dataDict = dataDict\n",
    "        self.childrenDict = None\n",
    "        self.classification = classification\n",
    "\n",
    "def occurrence(dataset,attribute):\n",
    "    dictionary = dataset #transfer data set into dictionary based on columns(will be a function)\n",
    "    values = entropies(dataset,attribute) #the entropy of each unique value in attribute\n",
    "    counts = 0\n",
    "    count={}\n",
    "    for i in values:\n",
    "        count[i] = 0\n",
    "    for i in range(len(dictionary[attribute])):\n",
    "            if dictionary[attribute][i] in values:\n",
    "                count[dictionary[attribute][i]] +=1\n",
    "\n",
    "    for i in count:\n",
    "        counts+= count[i]\n",
    "    for i in count:\n",
    "        count[i] = count[i]/counts\n",
    "    return count\n",
    "\n",
    "def attribute_entropies(dataset):\n",
    "    attributes= dataset\n",
    "    values = {}\n",
    "    for i in attributes:\n",
    "        column = entropies(dataset,i)\n",
    "        number = occurrence(dataset,i)\n",
    "        values[i]=0\n",
    "        for j in column:\n",
    "            values[i] += (column[j]*number[j])\n",
    "    values.popitem()\n",
    "    return values #  multiply of the fraction of how many values are\n",
    "\n",
    "def read_file(filename):\n",
    "    dictionary = {}\n",
    "    t = []\n",
    "    second = []\n",
    "    third = []\n",
    "    f = open(filename, \"r\")\n",
    "    \n",
    "    # get the number of rows\n",
    "    m = f.readlines()\n",
    "    count = 0\n",
    "    for i in m:\n",
    "        count +=1\n",
    "        \n",
    "    # append each line in the file to a list\n",
    "    for i in m:\n",
    "        d = i.strip()\n",
    "        t.append(d)\n",
    "    # adjusting the list (t) by removing \\t and adding them to another list   \n",
    "    for i in range(len(t)):\n",
    "        a = (t[i].replace('\\t',','))\n",
    "        second.append(a)\n",
    "     # spliting the strings in list (second)  and adding them to another list      \n",
    "    for i in second:\n",
    "        a = i.split(',')\n",
    "        third.append(a)\n",
    "        \n",
    "    # Creating the dictionary\n",
    "    size = len(third[0])\n",
    "    for i in range ((size)):\n",
    "        dictionary[third[0][i]] = []\n",
    "    for j in range (len(third)-1):\n",
    "        for i in range (size):\n",
    "            dictionary[third[0][i]].append(third[j+1][i])\n",
    "        \n",
    "    return dictionary\n",
    "\n",
    "def unique(lst):\n",
    "    lst2 = []\n",
    "    for i in lst:\n",
    "        if i not in lst2:\n",
    "            lst2.append(i)\n",
    "    return lst2\n",
    "\n",
    "def entropies(dataset,attribute):\n",
    "    dictionary = dataset #transfer data set into dictionary based on columns (will be a function)\n",
    "    attributes = []\n",
    "    values = [] #values in attribute\n",
    "    entropies = {}\n",
    "    for i in dictionary:\n",
    "        attributes.append(i)\n",
    "    for i in range(len(dictionary[attribute])):\n",
    "        values.append(dictionary[attribute][i])\n",
    "    unique_val = unique(values) #unique will be a seperate function that returns a list of unique values\n",
    "\n",
    "    uni = {} #dictionary 2\n",
    "    for i in unique_val:\n",
    "        uni[i] = [0,0]\n",
    "    #create a dictionary of unique values in format value:[number of yes,number of no]\n",
    "    for i in range(len(values)): #len values because we want the number of rows in dataset\n",
    "        if dictionary[attributes[-1]][i] == 'yes':\n",
    "            for j in range(len(unique_val)):\n",
    "                if dictionary[attribute][i] == unique_val[j]:\n",
    "                    uni[unique_val[j]][0] +=1\n",
    "        elif dictionary[attributes[-1]][i] == 'no':\n",
    "            for j in range(len(unique_val)):\n",
    "                if dictionary [attribute][i] == unique_val[j]:\n",
    "                    uni[unique_val[j]][1] +=1\n",
    "    #calculate enolopies for each value\n",
    "    for i in (uni):\n",
    "        if (-uni[i][0]) == 0 or (-uni[i][1]) == 0:\n",
    "            entropies[i] = 0\n",
    "        else:\n",
    "            entropies[i] = (-uni[i][0])/(uni[i][0]+uni[i][1])*math.log(uni[i][0]/(uni[i][0]+uni[i][1])) - (uni[i][1]/(uni[i][0]+uni[i][1])*math.log(uni[i][1]/(uni[i][0]+uni[i][1])))\n",
    "    for i in ((uni)):\n",
    "        uni[i] = entropies [i] # assosiate each value with its entropy\n",
    "    return uni\n",
    "\n",
    "def training_set_accuracy(node,dict):\n",
    "    data = dict\n",
    "    row = {}\n",
    "    accurate = 0\n",
    "    unaccurate = 0\n",
    "    elements=[]\n",
    "    for j in data:\n",
    "        size = len(data[j])\n",
    "\n",
    "    for i in range((size)):\n",
    "        for j in data.keys():\n",
    "            element = data[j].pop(0)\n",
    "            row[j] = element\n",
    "            data[j].append(element)\n",
    "        root = Node(data,'yes')\n",
    "        tree = build_tree(root)\n",
    "        x = query(root,row)\n",
    "        if x[0] == 'y':\n",
    "            if row[list(row.keys())[-1]] == 'yes':\n",
    "                accurate+=1\n",
    "            else:\n",
    "                unaccurate+=1\n",
    "        elif x[0] == 'n':\n",
    "            if row[list(row.keys())[-1]] == 'no':\n",
    "                accurate+=1\n",
    "            else:\n",
    "                unaccurate+=1\n",
    "    return (accurate/(accurate+unaccurate) *100)\n",
    "\n",
    "def row_acc(dict):\n",
    "    data = dict\n",
    "    row = {}\n",
    "    accurate = 0\n",
    "    unaccurate = 0\n",
    "    elements=[]\n",
    "    for j in data:\n",
    "        size = len(data[j])\n",
    "\n",
    "    for i in range((size)):\n",
    "        for j in data.keys():\n",
    "            element = data[j].pop(0)\n",
    "            row[j] = element\n",
    "            elements.append(element)\n",
    "        root = Node(data,'yes')\n",
    "        tree = build_tree(root)\n",
    "        x = query(root,row)\n",
    "        if x[0] == 'y':\n",
    "            if row[list(row.keys())[-1]] == 'yes':\n",
    "                accurate+=1\n",
    "            else:\n",
    "                unaccurate+=1\n",
    "        elif x[0] == 'n':\n",
    "            if row[list(row.keys())[-1]] == 'no':\n",
    "                accurate+=1\n",
    "            else:\n",
    "                unaccurate+=1\n",
    "    \n",
    "        for j in data.keys():\n",
    "            v = elements.pop(0)\n",
    "            data[j].append(v)\n",
    "    return (accurate/(accurate+unaccurate) *100)\n",
    "    \n",
    "def traverse(node,):\n",
    "    tree = build_tree(node)\n",
    "\n",
    "    if node.childrenDict == None:\n",
    "        return 0\n",
    "    for key in node.childrenDict:\n",
    "        print(node._featureSplit + \" = \" + key + \": \" + node.childrenDict[key].classification)\n",
    "        traverse(node.childrenDict[key])\n",
    "def query(node,dict):\n",
    "    node = node\n",
    "    while node.childrenDict != None:\n",
    "        feature = node._featureSplit\n",
    "        split = dict[feature]\n",
    "        if split in node.childrenDict.keys():\n",
    "            node = node.childrenDict[split]\n",
    "        else:\n",
    "            return node.classification\n",
    "    return node.classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.05497501135848\n"
     ]
    }
   ],
   "source": [
    "data = read_file('titanic2.txt')\n",
    "node = Node(data,'yes')\n",
    "build_tree(node)\n",
    "\n",
    "print(training_set_accuracy(node,data))\n",
    "#print( traverse(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

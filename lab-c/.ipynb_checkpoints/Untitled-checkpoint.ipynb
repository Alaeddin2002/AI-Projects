{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': ['tiny',\n",
       "  'tiny',\n",
       "  'tiny',\n",
       "  'small',\n",
       "  'small',\n",
       "  'small',\n",
       "  'small',\n",
       "  'small',\n",
       "  'small',\n",
       "  'medium',\n",
       "  'medium',\n",
       "  'medium',\n",
       "  'large',\n",
       "  'large',\n",
       "  'enormous'],\n",
       " 'color': ['white',\n",
       "  'white',\n",
       "  'brown',\n",
       "  'gray',\n",
       "  'gray',\n",
       "  'orange',\n",
       "  'gray',\n",
       "  'gray',\n",
       "  'brown',\n",
       "  'gray',\n",
       "  'gray',\n",
       "  'brown',\n",
       "  'brown',\n",
       "  'yellow',\n",
       "  'brown'],\n",
       " 'earshape': ['pointed',\n",
       "  'pointed',\n",
       "  'pointed',\n",
       "  'pointed',\n",
       "  'pointed',\n",
       "  'pointed',\n",
       "  'folded',\n",
       "  'pointed',\n",
       "  'folded',\n",
       "  'folded',\n",
       "  'pointed',\n",
       "  'pointed',\n",
       "  'folded',\n",
       "  'folded',\n",
       "  'folded'],\n",
       " 'tail': ['yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'no',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes'],\n",
       " 'iscat': ['no',\n",
       "  'yes',\n",
       "  'no',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'yes',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def read(filename):\n",
    "    dictionary = {}\n",
    "    t = []\n",
    "    second = []\n",
    "    third = []\n",
    "    f = open(filename, \"r\")\n",
    "    \n",
    "    # get the number of rows\n",
    "    m = f.readlines()\n",
    "    count = 0\n",
    "    for i in m:\n",
    "        count +=1\n",
    "        \n",
    "    # append each line in the file to a list\n",
    "    for i in m:\n",
    "        d = i.strip()\n",
    "        t.append(d)\n",
    "    # adjusting the list (t) by removing \\t and adding them to another list   \n",
    "    for i in range(len(t)):\n",
    "        a = (t[i].replace('\\t',','))\n",
    "        second.append(a)\n",
    "     # spliting the strings in list (second)  and adding them to another list      \n",
    "    for i in second:\n",
    "        a = i.split(',')\n",
    "        third.append(a)\n",
    "        \n",
    "    # Creating the dictionary\n",
    "    size = len(third[0])\n",
    "    for i in range ((size)):\n",
    "        dictionary[third[0][i]] = []\n",
    "    for j in range (len(third)-1):\n",
    "        for i in range (size):\n",
    "            dictionary[third[0][i]].append(third[j+1][i])\n",
    "        \n",
    "    return dictionary\n",
    "read('pets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(lst):\n",
    "    lst2 = []\n",
    "    for i in lst:\n",
    "        if i not in lst2:\n",
    "            lst2.append(i)\n",
    "    return lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tiny': 0.6365141682948128,\n",
       " 'small': 0.6365141682948128,\n",
       " 'medium': 0.6365141682948128,\n",
       " 'large': 0,\n",
       " 'enormous': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def entropies(dataset,attribute):\n",
    "    dictionary = read(dataset)#transfer data set into dictionary based on columns (will be a function)\n",
    "    attributes = []\n",
    "    values = [] #values in attribute\n",
    "    enelopies = {}\n",
    "    for i in dictionary:\n",
    "        attributes.append(i)\n",
    "    for i in range(len(dictionary[attribute])):\n",
    "        values.append(dictionary[attribute][i])\n",
    "    unique_val = unique(values) #unique will be a seperate function that returns a list of unique values\n",
    "\n",
    "    uni = {} #dictionary 2\n",
    "    for i in unique_val:\n",
    "        uni[i] = [0,0]\n",
    "    #create a dictionary of unique values in format value:[number of yes,number of no]\n",
    "    for i in range(len(values)): #len values because we want the number of rows in dataset\n",
    "        if dictionary[attributes[-1]][i] == 'yes':\n",
    "            for j in range(len(unique_val)):\n",
    "                if dictionary[attribute][i] == unique_val[j]:\n",
    "                    uni[unique_val[j]][0] +=1\n",
    "        elif dictionary[attributes[-1]][i] == 'no':\n",
    "            for j in range(len(unique_val)):\n",
    "                if dictionary [attribute][i] == unique_val[j]:\n",
    "                    uni[unique_val[j]][1] +=1\n",
    "    #calculate enolopies for each value\n",
    "    for i in (uni):\n",
    "        if (-uni[i][0]) == 0 or (-uni[i][1]) == 0:\n",
    "            enelopies[i] = 0\n",
    "        else:\n",
    "            enelopies[i] = (-uni[i][0])/(uni[i][0]+uni[i][1])*math.log(uni[i][0]/(uni[i][0]+uni[i][1])) - (uni[i][1]/(uni[i][0]+uni[i][1])*math.log(uni[i][1]/(uni[i][0]+uni[i][1])))\n",
    "    for i in ((uni)):\n",
    "        uni[i] = enelopies [i] # assosiate each value with its entropy\n",
    "    \n",
    "    return uni\n",
    "\n",
    "entropies('pets.txt','size')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tiny': ['no', 66.66666666666666],\n",
       " 'small': ['yes', 66.66666666666666],\n",
       " 'medium': ['no', 66.66666666666666],\n",
       " 'large': ['no', 100.0],\n",
       " 'enormous': ['no', 100.0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plurality(dataset,attribute):\n",
    "    dictionary = read(dataset)#transfer data set into dictionary based on columns (will be a function)\n",
    "    attributes = []\n",
    "    values = [] #values in attribute\n",
    "    percentage = {}\n",
    "    enelopies = {}\n",
    "    for i in dictionary:\n",
    "        attributes.append(i)\n",
    "    for i in range(len(dictionary[attribute])):\n",
    "        values.append(dictionary[attribute][i])\n",
    "    unique_val = unique(values) #unique will be a seperate function that returns a list of unique values\n",
    "\n",
    "    uni = {} #dictionary 2\n",
    "    for i in unique_val:\n",
    "        uni[i] = [0,0]\n",
    "    #create a dictionary of unique values in format value:[number of yes,number of no]\n",
    "    for i in range(len(values)): #len values because we want the number of rows in dataset\n",
    "        if dictionary[attributes[-1]][i] == 'yes':\n",
    "            for j in range(len(unique_val)):\n",
    "                if dictionary[attribute][i] == unique_val[j]:\n",
    "                    uni[unique_val[j]][0] +=1\n",
    "        elif dictionary[attributes[-1]][i] == 'no':\n",
    "            for j in range(len(unique_val)):\n",
    "                if dictionary [attribute][i] == unique_val[j]:\n",
    "                    uni[unique_val[j]][1] +=1\n",
    "    for i in uni:\n",
    "        if uni[i][0] > uni[i][1]:\n",
    "            percentage[i] = ['yes',(uni[i][0]/ (uni[i][1]+uni[i][0])* 100)]\n",
    "        if uni[i][0] < uni[i][1]:\n",
    "            percentage[i] = ['no',((uni[i][1]/ (uni[i][0]+uni[i][1])) * 100)]\n",
    "    return percentage\n",
    "plurality('pets.txt','size')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tiny': 0.2,\n",
       " 'small': 0.4,\n",
       " 'medium': 0.2,\n",
       " 'large': 0.13333333333333333,\n",
       " 'enormous': 0.06666666666666667}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def occurrence(dataset,attribute):\n",
    "    dictionary = read(dataset)#transfer data set into dictionary based on columns(will be a function)\n",
    "    values = entropies(dataset,attribute) #the entropy of each unique value in attribute\n",
    "    counts = 0\n",
    "    attributes = []\n",
    "    for i in dictionary:\n",
    "        attributes.append(i)\n",
    "        \n",
    "    count={}\n",
    "    for i in values:\n",
    "        count[i] = 0\n",
    "    for i in range(len(dictionary[attribute])):\n",
    "            if dictionary[attribute][i] in values:\n",
    "                count[dictionary[attribute][i]] +=1\n",
    "                \n",
    "    for i in count:\n",
    "        counts+= count[i]\n",
    "    for i in count:\n",
    "        count[i] = count[i]/counts\n",
    "    return count\n",
    "occurrence('pets.txt','size')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 0.5092113346358502,\n",
       " 'color': 0.5364793041447,\n",
       " 'earshape': 0.5924014295049158,\n",
       " 'tail': 0.6083061237611429}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attribute_entropies(dataset):\n",
    "    attributes=read(dataset)\n",
    "    values = {}\n",
    "    for i in attributes:\n",
    "        column = entropies(dataset,i)\n",
    "        number = occurrence(dataset,i)\n",
    "        values[i]=0\n",
    "        for j in column:\n",
    "            values[i] += (column[j]*number[j])\n",
    "    values.popitem()       \n",
    "    return values #  multiply of the fraction of how many values are \n",
    "attribute_entropies('pets.txt')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tiny': 3, 'small': 6, 'medium': 3, 'large': 2, 'enormous': 1}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Importance(dataset,attribute):\n",
    "    dictionary = read(dataset)#transfer data set into dictionary based on columns(will be a function)\n",
    "    values = entropies(dataset,attribute) #the entropy of each unique value in attribute\n",
    "    yes = 0 # number of yes in state\n",
    "    no = 0 # number of no in state\n",
    "    attributes = []\n",
    "    for i in dictionary:\n",
    "        attributes.append(i)\n",
    "        \n",
    "    for i in range(len(dictionary[attribute])):\n",
    "        if dictionary[attributes[-1]][i] == 'yes':\n",
    "            yes+=1\n",
    "        if dictionary[attributes[-1]][i] == 'no':\n",
    "            no+=1\n",
    "    count={}\n",
    "    for i in values:\n",
    "        count[i] = 0\n",
    "    for i in range(len(dictionary[attribute])):\n",
    "            if dictionary[attribute][i] in values:\n",
    "                count[dictionary[attribute][i]] +=1\n",
    "        \n",
    "            \n",
    "    Entropy_of_current_state = -yes/(yes+no)*math.log(yes/(yes+no)) -no/(yes+no)*math.log(no/(yes+no))\n",
    "    sum_values = 0\n",
    "    for i in count:\n",
    "        sum_values  +=count[i]\n",
    "    for i in values:\n",
    "        Entropy_of_current_state -= ((count[i]/sum_values)*values[i])\n",
    "    return Entropy_of_current_state\n",
    "\n",
    "Importance('pets.txt','size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny\n",
      "tiny\n",
      "tiny\n",
      "small\n",
      "small\n",
      "small\n",
      "small\n",
      "small\n",
      "small\n",
      "medium\n",
      "medium\n",
      "medium\n",
      "large\n",
      "large\n",
      "enormous\n",
      "white\n",
      "white\n",
      "brown\n",
      "gray\n",
      "gray\n",
      "orange\n",
      "gray\n",
      "gray\n",
      "brown\n",
      "gray\n",
      "gray\n",
      "brown\n",
      "brown\n",
      "yellow\n",
      "brown\n",
      "pointed\n",
      "pointed\n",
      "pointed\n",
      "pointed\n",
      "pointed\n",
      "pointed\n",
      "folded\n",
      "pointed\n",
      "folded\n",
      "folded\n",
      "pointed\n",
      "pointed\n",
      "folded\n",
      "folded\n",
      "folded\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "yes\n",
      "no\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "yes\n",
      "no\n",
      "no\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "x = read('pets.txt')\n",
    "for j in x:\n",
    "    for i in range(len(x[j])):\n",
    "        print (x[j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Node() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1724e1a9ccc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pets.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-1724e1a9ccc4>\u001b[0m in \u001b[0;36msplit\u001b[0;34m(node, feature)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'no'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mnewNode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildrenDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Node() takes no arguments"
     ]
    }
   ],
   "source": [
    "def rebuild(dict,feature):\n",
    "    elements = {}\n",
    "    index = 0\n",
    "    for x in dict.keys():\n",
    "        if x == feature:\n",
    "            for value in dict[x]:\n",
    "                if value in elements.keys():\n",
    "                    elements[value].append(index)\n",
    "                else:\n",
    "                    elements[value] = []\n",
    "                    elements[value].append(index)\n",
    "                    index += 1\n",
    "    outerDict = {}\n",
    "    for x in elements.keys():\n",
    "        innerDict = {}\n",
    "        for y in dict.keys():\n",
    "            if y != feature:\n",
    "                innerDict[y] = []\n",
    "                for value in elements[x]:\n",
    "                    innerDict[y].append(dict[y][value])\n",
    "                outerDict[x] = innerDict\n",
    "    return outerDict\n",
    "\n",
    "def split(node,feature):\n",
    "    node._featureSplit = feature\n",
    "    data = rebuild(node._dataDict,feature)\n",
    "    for key in data.keys():\n",
    "        yesCount = 0\n",
    "        noCount = 0\n",
    "        values = list(data[key].values())\n",
    "        classificationCol = values[len(values)-1]\n",
    "        for value in classificationCol:\n",
    "            if value == 'yes':\n",
    "                yesCount += 1\n",
    "            else:\n",
    "                noCount += 1\n",
    "        if yesCount > noCount:\n",
    "            classification = 'yes'\n",
    "        else:\n",
    "            classification = 'no'\n",
    "        newNode = Node(data[key].values(),classification)\n",
    "        data[key] = newNode\n",
    "    node.childrenDict = data\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def init(self,dataDict,classification):\n",
    "        self._featureSplit = None\n",
    "        self._dataDict = dataDict\n",
    "        self.childrenDict = None\n",
    "        self.classification = classification\n",
    "        \n",
    "rebuild(read('pets.txt'),'size')\n",
    "\n",
    "split(node,'size')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
